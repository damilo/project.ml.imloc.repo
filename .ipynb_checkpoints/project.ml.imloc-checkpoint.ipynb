{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification & Localization of Objects in Images\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "introduction and problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "familiarize yourself with the data, helps you to better understand and justify your results\n",
    "\n",
    "statistics, visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    The dataset 'tiny-imagenet-200' consists of 3 main folders 'train', 'val', 'test'.\n",
    "</p>\n",
    "\n",
    "- folder 'train'\n",
    "  - contains 200 folders, one for each class\n",
    "  - each class folder has a subfolder 'images' with 500 samples and a file with box coordinates of all samples\n",
    "  - there are 200 * 500 = 100'000 samples in total\n",
    "- folder 'val'\n",
    "  - contains 1 folder 'images' with 10'000 samples and a file holding the annotations to all samples\n",
    "- folder 'test'\n",
    "  - contains 1 folder 'images' with 10'000 samples\n",
    "\n",
    "<p>\n",
    "There is a file with all WordNet IDs of this dataset 'wnids.txt'.\n",
    "<p>\n",
    "<p>\n",
    "There is a file linking all <i>known</i> WordNet IDs and their descriptive name(s). It is useful in conjunction with the 'wnids.txt' to name the classes.\n",
    "</p>\n",
    "\n",
    "<pre>\n",
    "+-- tiny-imagenet-200\n",
    "    +--- train (200 folders)\n",
    "         +--- n01443537\n",
    "              +--- images (500 files)\n",
    "                   |--- n01443537_0.JPEG\n",
    "                   |--- ...\n",
    "                   |--- n01443537_499.JPEG\n",
    "              |--- n01443537_boxes.txt\n",
    "         +--- ...\n",
    "    +--- val\n",
    "        |--- val_annotations.txt\n",
    "        +--- images (10,000 files)\n",
    "             |--- val_0.JPEG\n",
    "             |--- ...\n",
    "             |--- val_9999.JPEG\n",
    "    +--- test\n",
    "         +--- images (10,000 files)\n",
    "              |--- test_0.JPEG\n",
    "              |--- ...\n",
    "              |--- test_9999.JPEG\n",
    "    |--- wnids.txt\n",
    "    |--- words.txt\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DS_PATH = os.path.join ('..', 'datasets', 'tiny-imagenet-200')\n",
    "DS_TRAIN_PATH = os.path.join (DS_PATH, 'train')\n",
    "DS_VAL_PATH = os.path.join (DS_PATH, 'val')\n",
    "DS_TEST_PATH = os.path.join (DS_PATH, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the properties of the images (only one picture)\n",
    "# display an image\n",
    "# annotations of train images\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "%matplotlib inline\n",
    "\n",
    "DS_TRAIN_IMAGE = os.path.join (DS_TRAIN_PATH, 'n01443537', 'images', 'n01443537_0.JPEG')\n",
    "train_img = io.imread (DS_TRAIN_IMAGE)\n",
    "\n",
    "DS_TRAIN_IMAGE_ANNOT = os.path.join (DS_TRAIN_PATH, 'n01443537', 'n01443537_boxes.txt')\n",
    "img_annot_df = pd.read_csv (DS_TRAIN_IMAGE_ANNOT, sep='\\t', header=None, names=['image', 'box_x1', 'box_y1', 'box_x2', 'box_y2'])\n",
    "print ('box of image object:')\n",
    "print (img_annot_df.head (1), end='\\n\\n')\n",
    "\n",
    "print ('shape of image object:', train_img.shape, end='\\n\\n')\n",
    "\n",
    "print ('image object:')\n",
    "fig, axs = plt.subplots (1, 1)\n",
    "axs.set_ylabel ('height (y)')\n",
    "axs.set_xlabel ('width (x)')\n",
    "axs.imshow (train_img)\n",
    "rect = patches.Rectangle ((img_annot_df.iloc[0][1],img_annot_df.iloc[0][2]),\n",
    "                          (img_annot_df.iloc[0][3] - img_annot_df.iloc[0][1]),\n",
    "                          (img_annot_df.iloc[0][4] - img_annot_df.iloc[0][2]),\n",
    "                          linewidth=2,edgecolor='r',facecolor='none')\n",
    "axs.add_patch (rect)\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wnid file (wnids.txt)\n",
    "holds all WordNet IDs of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the wnid annotations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "WNID_FILE = os.path.join (DS_PATH, 'wnids.txt')\n",
    "wnid_df = pd.read_csv (WNID_FILE, header=None, names=['wnid'])\n",
    "\n",
    "print (wnid_df.info ())\n",
    "print (wnid_df.describe ())\n",
    "print (wnid_df.sample (3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### words file (words.txt)\n",
    "holds all WordNet IDs and their description(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "WNID_WORDS_FILE = os.path.join (DS_PATH, 'words.txt')\n",
    "wnid_words_df = pd.read_csv (WNID_WORDS_FILE, sep='\\t', header=None, names=['wnid', 'desc'])\n",
    "\n",
    "print (wnid_words_df.info ())\n",
    "print (wnid_words_df.describe ())\n",
    "print (wnid_words_df.sample (3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the description of a wnid\n",
    "#wnid = wnid_df['wnid'].sample ().values[0]\n",
    "wnid = 'n01443537'\n",
    "wnid_desc = wnid_words_df[wnid_words_df['wnid'] == wnid]['desc'].values[0]\n",
    "\n",
    "print (wnid, wnid_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "some other algorithm / software / result to compare this algorithm against (by using the defined metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification: random guess\n",
    "# localization: - tbd (for example the mean of all contestors of this Kaggle competition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split project here into\n",
    "# - multiclass classification\n",
    "# - regression for localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric\n",
    "used metric for classification is categorial cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train data__\n",
    "<pre>\n",
    "+-- dataset\\tiny-imagenet-200\n",
    "    |+-- train (200 directories)\n",
    "         |+-- n01443537\n",
    "              |+-- images (500 files)\n",
    "                   |--- n01443537_0.JPEG\n",
    "                   |--- ...\n",
    "                   |--- n01443537_499.JPEG\n",
    "              |--- n01443537_boxes.txt\n",
    "         |+-- ...\n",
    "         |+-- n12267677\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all images from training dataset\n",
    "from collections import defaultdict\n",
    "\n",
    "# get a list of all image class directories\n",
    "train_data = defaultdict (list)\n",
    "train_path_entries = os.listdir (DS_TRAIN_PATH)\n",
    "for i in range (len (train_path_entries)):\n",
    "    entry_i_imgs_p = DS_TRAIN_PATH + os.sep + train_path_entries[i] + os.sep + 'images'\n",
    "    \n",
    "    # add data as key-value pair for later use\n",
    "    k = train_path_entries[i]\n",
    "    v = [entry_i_imgs_p + os.sep + img for img in os.listdir (entry_i_imgs_p)]\n",
    "    train_data[k] = v\n",
    "\n",
    "print ('Now there are {} keys (classes) in the dictionary, each holding {} values (image paths).'\\\n",
    "       .format (len (train_data.keys ()), len (train_data[list (train_data.keys ())[0]])))\n",
    "print ()\n",
    "print ('Example:',\\\n",
    "       'key (class) =', list (train_data.keys ())[42],\\\n",
    "       ', values (image paths) =',\\\n",
    "       train_data[list (train_data.keys())[42]][:2], '...',\\\n",
    "       train_data[list (train_data.keys())[42]][-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN expects tensors in form (#, w, h, d) > read in images and create tensor per class.\n",
    "\n",
    "[!] mixed BW and RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.color import gray2rgb\n",
    "\n",
    "def image_path_to_tensor (img_path_list):\n",
    "    img_list = []\n",
    "    for img_path in img_path_list:\n",
    "        img_arr = imread (img_path)\n",
    "        # check depth for BW image\n",
    "        if (len (img_arr.shape) < 3):\n",
    "            img_arr = gray2rgb (img_arr)\n",
    "        \n",
    "        img_arr = np.expand_dims (img_arr, axis=0)\n",
    "        img_list.append (img_arr)\n",
    "    \n",
    "    return np.vstack (img_list)\n",
    "    \n",
    "# unit test\n",
    "# (image_path_to_tensor (train_data[list (train_data.keys())[42]][:5])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_tensor_list = []\n",
    "train_data_targets_list = []\n",
    "i = 1\n",
    "for img_class, img_paths in train_data.items ():\n",
    "    #pass\n",
    "    # read images\n",
    "    print ('\\rReading images of wnid class {}, ({:4} / {:4})'.format (img_class, i, len (train_data.keys ())), end='', flush=True)\n",
    "    img_class_tensor = image_path_to_tensor (train_data[img_class])\n",
    "    # add images to train data tensor\n",
    "    train_data_tensor_list.append (img_class_tensor)\n",
    "    # write image class to target variable\n",
    "    train_data_targets_list.append ([img_class for x in range (len (train_data[img_class]))])\n",
    "    # blub\n",
    "    i += 1\n",
    "\n",
    "train_data_tensor = (np.vstack (train_data_tensor_list)).astype (dtype='f4', copy=False) / 255 # incl. normalization [0, 255] -> [0, 1]\n",
    "train_data_targets = np.hstack (train_data_targets_list)\n",
    "\n",
    "# clean up\n",
    "del train_data_tensor_list\n",
    "del train_data_targets_list\n",
    "del train_data\n",
    "\n",
    "print ('\\n')\n",
    "print ('Shape of train data tensor:', train_data_tensor.shape)\n",
    "print ('Shape of train data target vector:', train_data_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__validation data__\n",
    "<pre>\n",
    "+-- dataset\\tiny-imagenet-200\n",
    "    |+-- val\n",
    "        |--- val_annotations.txt\n",
    "        |+-- images (10,000 files)\n",
    "             |--- val_0.JPEG\n",
    "             |--- ...\n",
    "             |--- val_9999.JPEG\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# get a list of all image class directories\n",
    "val_data = defaultdict (list)\n",
    "entry_i_imgs_p = DS_VAL_PATH + os.sep + 'images'\n",
    "k = 'val_imgs'\n",
    "v = [entry_i_imgs_p + os.sep + img for img in os.listdir (entry_i_imgs_p)]\n",
    "val_data[k] = v\n",
    "\n",
    "# image annotations (contain wnid class)\n",
    "DS_VAL_PATH_ANNOTS = DS_VAL_PATH + os.sep + 'val_annotations.txt'\n",
    "val_annots_df = pd.read_csv (DS_VAL_PATH_ANNOTS, sep='\\t', header=None, names=['image', 'wnid', 'box_x1', 'box_y1', 'box_x2', 'box_y2'])\n",
    "\n",
    "\n",
    "print ('Now there are {} values (image paths) in validation set.'\\\n",
    "       .format (len (val_data['val_imgs'])))\n",
    "print ()\n",
    "print ('Example:',\\\n",
    "       'key =', list (val_data.keys ())[0],\\\n",
    "       ', values (image paths) =',\\\n",
    "       val_data[list (val_data.keys())[0]][:2], '...',\\\n",
    "       val_data[list (val_data.keys())[0]][-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all images from validation dataset\n",
    "val_data_tensor_list = []\n",
    "val_data_targets_list = []\n",
    "i = 1\n",
    "for img_path in val_data['val_imgs']:\n",
    "    # read images\n",
    "    print ('\\rReading validation images, ({:5} / {:5})'.format (i, len (val_data['val_imgs'])), end='', flush=True)\n",
    "    img_class_tensor = image_path_to_tensor ([img_path])\n",
    "    # add images to  tensor\n",
    "    val_data_tensor_list.append (img_class_tensor)\n",
    "    # write image class to target variable\n",
    "    img_name = os.path.basename (img_path)\n",
    "    img_wnid = val_annots_df[val_annots_df['image'] == img_name]['wnid'].values[0]\n",
    "    val_data_targets_list.append (img_wnid)\n",
    "    # blub\n",
    "    i += 1\n",
    "\n",
    "val_data_tensor = (np.vstack (val_data_tensor_list)).astype (dtype='f4', copy=False) / 255 # incl. normalization [0, 255] -> [0, 1]\n",
    "val_data_targets = np.hstack (val_data_targets_list)\n",
    "\n",
    "# clean up\n",
    "del val_data_tensor_list\n",
    "del val_data_targets_list\n",
    "del val_data\n",
    "\n",
    "print ('\\n')\n",
    "print ('Shape of val data tensor:', val_data_tensor.shape)\n",
    "print ('Shape of val data target vector:', val_data_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode targets\n",
    "import pandas as pd\n",
    "\n",
    "train_data_targets_onehot = pd.get_dummies (train_data_targets)\n",
    "\n",
    "val_data_targets_onehot = pd.DataFrame (\n",
    "    data= np.zeros ((val_data_targets.shape[0], train_data_targets_onehot.shape[1]),  dtype=train_data_targets_onehot.values.dtype),\n",
    "    columns=train_data_targets_onehot.columns.values)\n",
    "\n",
    "for i in range (val_data_targets.shape[0]):\n",
    "    cur_wnid = val_data_targets[i]\n",
    "    val_data_targets_onehot.iloc[i][cur_wnid] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make arrays of everything (i.e. get rid of index and column)\n",
    "train_targets = train_data_targets_onehot.values\n",
    "val_targets = val_data_targets_onehot.values\n",
    "\n",
    "# save the columns once to identify the wnid later\n",
    "targets_names = train_data_targets_onehot.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('train data:')\n",
    "print ('  ', 'type :', type (train_data_tensor))\n",
    "print ('  ', 'dtype:', train_data_tensor.dtype)\n",
    "print ('  ', 'shape:', train_data_tensor.shape)\n",
    "\n",
    "print ()\n",
    "\n",
    "print ('validation data:')\n",
    "print ('  ', 'type :', type (val_data_tensor))\n",
    "print ('  ', 'dtype:', val_data_tensor.dtype)\n",
    "print ('  ', 'shape:', val_data_tensor.shape)\n",
    "\n",
    "print ()\n",
    "\n",
    "print ('target data:')\n",
    "print ('  ', 'type :', type (train_targets))\n",
    "print ('  ', 'dtype:', train_targets.dtype)\n",
    "print ('  ', 'shape:', train_targets.shape)\n",
    "print ('  ', 'names:', targets_names[:3], '...', targets_names[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "RND_STATE = 42\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data_shuffled, _, train_targets_shuffled, _ = train_test_split (train_data_tensor, train_targets,\n",
    "                                                                test_size=0.0, random_state=RND_STATE, shuffle=True)\n",
    "\n",
    "val_data_shuffled, _, val_targets_shuffled, _ = train_test_split (val_data_tensor, val_targets,\n",
    "                                                                  test_size=0.0, random_state=RND_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "del train_data_tensor\n",
    "del train_targets\n",
    "del val_data_tensor\n",
    "del val_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, optimizers\n",
    "\n",
    "input_shape = (64,64,3)#train_data_shuffled.shape[1:]\n",
    "n_outputs = 200\n",
    "\n",
    "# input layer\n",
    "inputs = layers.Input (shape=input_shape, name='input')\n",
    "\n",
    "# hidden layer\n",
    "net = layers.Conv2D (\n",
    "    filters = 16,\n",
    "    kernel_size = (5,5),\n",
    "    strides = (1,1),\n",
    "    padding = 'same',\n",
    "    activation = 'elu',\n",
    "    name = 'conv_11'\n",
    ") (inputs)\n",
    "\n",
    "net = layers.MaxPooling2D (\n",
    "    pool_size = (2,2),\n",
    "    name = 'pool_1'\n",
    ") (net)\n",
    "\n",
    "net = layers.Conv2D (\n",
    "    filters = 32,\n",
    "    kernel_size = (5,5),\n",
    "    strides = (1,1),\n",
    "    padding = 'same',\n",
    "    activation = 'elu',\n",
    "    name = 'conv_21'\n",
    ") (net)\n",
    "\n",
    "net = layers.MaxPooling2D (\n",
    "    pool_size = (2,2),\n",
    "    name = 'pool_2'\n",
    ") (net)\n",
    "\n",
    "net = layers.Conv2D (\n",
    "    filters = 64,\n",
    "    kernel_size = (5,5),\n",
    "    strides = (1,1),\n",
    "    padding = 'same',\n",
    "    activation = 'elu',\n",
    "    name = 'conv_31'\n",
    ") (net)\n",
    "\n",
    "net = layers.MaxPooling2D (\n",
    "    pool_size = (2,2),\n",
    "    name = 'pool_3'\n",
    ") (net)\n",
    "\n",
    "net = layers.Flatten (\n",
    "    name = 'flat_3'\n",
    ") (net)\n",
    "\n",
    "net = layers.Dense (\n",
    "    units = 1024,\n",
    "    activation = 'elu',\n",
    "    name = 'fc_4'\n",
    ") (net)\n",
    "\n",
    "# output layer\n",
    "outputs = layers.Dense (\n",
    "    units = n_outputs,\n",
    "    activation = 'linear',\n",
    "    name = 'output'\n",
    ") (net)\n",
    "\n",
    "# create optimizer\n",
    "opt_sgd = optimizers.SGD (lr=0.001)\n",
    "\n",
    "# build and compile model\n",
    "clf = models.Model (inputs=inputs, outputs=outputs, name='imloc.clf')\n",
    "clf.compile (optimizer=opt_sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"imloc.clf\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv_11 (Conv2D)             (None, 64, 64, 16)        1216      \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_21 (Conv2D)             (None, 32, 32, 32)        12832     \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_31 (Conv2D)             (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flat_3 (Flatten)             (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc_4 (Dense)                 (None, 1024)              4195328   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 200)               205000    \n",
      "=================================================================\n",
      "Total params: 4,465,640\n",
      "Trainable params: 4,465,640\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clf.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "checkpointer = ModelCheckpoint (\n",
    "                    filepath='project.ml.imloc.weights.best.hdf5', \n",
    "                    verbose=1,\n",
    "                    save_best_only=True)\n",
    "\n",
    "history = clf.fit (train_data_shuffled, train_targets_shuffled,\n",
    "          validation_data=(val_data_shuffled, val_targets_shuffled),\n",
    "          epochs=epochs, batch_size=100, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric\n",
    "define the metric to measure the quality of the learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "split data, define and train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Validation\n",
    "results and justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list dataset directory with number of folders and files\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = os.path.join ('dataset', 'tiny-imagenet-200')\n",
    "\n",
    "print ('+--', ds_path)\n",
    "path_entries = os.listdir (ds_path)\n",
    "num_dirs = 0\n",
    "num_files = 0\n",
    "for entry in path_entries:\n",
    "    entry_path = os.path.join (ds_path, entry)\n",
    "    if (os.path.isdir (entry_path)):\n",
    "        print ('    |+--', entry)\n",
    "        num_dirs+=1\n",
    "    if (os.path.isfile (entry_path)):\n",
    "        print ('    |---', entry)\n",
    "        num_files+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('directories:', num_dirs, ', files:', num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_path = os.path.join (ds_path, 'test')\n",
    "\n",
    "print ('+--', ds_test_path)\n",
    "num_dirs = 0\n",
    "num_files = 0\n",
    "path_entries = os.listdir (ds_test_path)\n",
    "for entry in path_entries:\n",
    "    entry_path = os.path.join (ds_test_path, entry)\n",
    "    if (os.path.isdir (entry_path)):\n",
    "        print ('    |+--', entry)\n",
    "        num_dirs+=1\n",
    "    if (os.path.isfile (entry_path)):\n",
    "        print ('    |---', entry)\n",
    "        num_files+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('directories:', num_dirs, ', files:', num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_images_path = os.path.join (ds_test_path, 'images')\n",
    "\n",
    "print ('+--', ds_test_images_path)\n",
    "num_dirs = 0\n",
    "num_files = 0\n",
    "path_entries = os.listdir (ds_test_images_path)\n",
    "for entry in path_entries:\n",
    "    entry_path = os.path.join (ds_test_images_path, entry)\n",
    "    if (os.path.isdir (entry_path)):\n",
    "        print ('    |+--', entry)\n",
    "        num_dirs+=1\n",
    "    if (os.path.isfile (entry_path)):\n",
    "        print ('    |---', entry)\n",
    "        num_files+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('directories:', num_dirs, ', files:', num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val_path = os.path.join (ds_path, 'val')\n",
    "\n",
    "print ('+--', ds_val_path)\n",
    "num_dirs = 0\n",
    "num_files = 0\n",
    "path_entries = os.listdir (ds_val_path)\n",
    "for entry in path_entries:\n",
    "    entry_path = os.path.join (ds_val_path, entry)\n",
    "    if (os.path.isdir (entry_path)):\n",
    "        print ('    |+--', entry)\n",
    "        num_dirs+=1\n",
    "    if (os.path.isfile (entry_path)):\n",
    "        print ('    |---', entry)\n",
    "        num_files+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('directories:', num_dirs, ', files:', num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val_images_path = os.path.join (ds_val_path, 'images')\n",
    "\n",
    "print ('+--', ds_val_images_path)\n",
    "num_dirs = 0\n",
    "num_files = 0\n",
    "path_entries = os.listdir (ds_val_images_path)\n",
    "for entry in path_entries:\n",
    "    entry_path = os.path.join (ds_val_images_path, entry)\n",
    "    if (os.path.isdir (entry_path)):\n",
    "        print ('    |+--', entry)\n",
    "        num_dirs+=1\n",
    "    if (os.path.isfile (entry_path)):\n",
    "        print ('    |---', entry)\n",
    "        num_files+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('directories:', num_dirs, ', files:', num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_path = os.path.join (ds_path, 'train')\n",
    "\n",
    "print ('+--', ds_train_path)\n",
    "num_dirs = 0\n",
    "num_files = 0\n",
    "path_entries = os.listdir (ds_train_path)\n",
    "for entry in path_entries:\n",
    "    entry_path = os.path.join (ds_train_path, entry)\n",
    "    if (os.path.isdir (entry_path)):\n",
    "        print ('    |+--', entry)\n",
    "        num_dirs+=1\n",
    "    if (os.path.isfile (entry_path)):\n",
    "        print ('    |---', entry)\n",
    "        num_files+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('directories:', num_dirs, ', files:', num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_wnid_path = os.path.join (ds_train_path, 'n01443537')\n",
    "\n",
    "print ('+--', ds_train_wnid_path)\n",
    "num_dirs = 0\n",
    "num_files = 0\n",
    "path_entries = os.listdir (ds_train_wnid_path)\n",
    "for entry in path_entries:\n",
    "    entry_path = os.path.join (ds_train_wnid_path, entry)\n",
    "    if (os.path.isdir (entry_path)):\n",
    "        print ('    |+--', entry)\n",
    "        num_dirs+=1\n",
    "    if (os.path.isfile (entry_path)):\n",
    "        print ('    |---', entry)\n",
    "        num_files+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('directories:', num_dirs, ', files:', num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_wnid_images_path = os.path.join (ds_train_wnid_path, 'images')\n",
    "\n",
    "print ('+--', ds_train_wnid_images_path)\n",
    "num_dirs = 0\n",
    "num_files = 0\n",
    "path_entries = os.listdir (ds_train_wnid_images_path)\n",
    "for entry in path_entries:\n",
    "    entry_path = os.path.join (ds_train_wnid_images_path, entry)\n",
    "    if (os.path.isdir (entry_path)):\n",
    "        print ('    |+--', entry)\n",
    "        num_dirs+=1\n",
    "    if (os.path.isfile (entry_path)):\n",
    "        print ('    |---', entry)\n",
    "        num_files+=1\n",
    "print ('directories:', num_dirs, ', files:', num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('directories:', num_dirs, ', files:', num_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
